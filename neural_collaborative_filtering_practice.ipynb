{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-23T05:34:39.013924Z",
     "start_time": "2024-05-23T05:34:39.009579Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import roc_auc_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "class MovieLensDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, ratings):\n",
    "        data = ratings.copy().to_numpy()\n",
    "        self.items = data[:, :2].astype(np.int32) - 1\n",
    "        self.targets = self.__preprocess_target(data[:, 2]).astype(np.float32)\n",
    "        self.field_dims = np.max(self.items, axis=0) + 1\n",
    "        self.user_field_idx = np.array((0, ), dtype=np.int64)\n",
    "        self.item_field_idx = np.array((1,), dtype=np.int64)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.targets.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.items[index], self.targets[index]\n",
    "\n",
    "    def __preprocess_target(self, target):\n",
    "        target = target / 5.\n",
    "        return target"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T05:34:40.326674Z",
     "start_time": "2024-05-23T05:34:40.324524Z"
    }
   },
   "id": "ac8181895880d8d5"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "class MultiLayerPerceptron(torch.nn.Module):\n",
    "    def __init__(self, input_dim, embed_dims, dropout, output_layer=True):\n",
    "        super().__init__()\n",
    "        layers = list()\n",
    "        for embed_dim in embed_dims:\n",
    "            layers.append(torch.nn.Linear(input_dim, embed_dim))\n",
    "            layers.append(torch.nn.BatchNorm1d(embed_dim))\n",
    "            layers.append(torch.nn.ReLU())\n",
    "            layers.append(torch.nn.Dropout(p=dropout))\n",
    "            input_dim = embed_dim\n",
    "        if output_layer:\n",
    "            layers.append(torch.nn.Linear(input_dim, 1))\n",
    "        self.mlp = torch.nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.mlp(x)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T05:34:42.031973Z",
     "start_time": "2024-05-23T05:34:42.029873Z"
    }
   },
   "id": "7be1a91a106a3449"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "class FeaturesEmbedding(torch.nn.Module):\n",
    "    def __init__(self, field_dims, embed_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = torch.nn.Embedding(sum(field_dims), embed_dim)\n",
    "        self.offsets = np.array((0, *np.cumsum(field_dims)[:-1]), dtype=np.int64)\n",
    "        torch.nn.init.xavier_uniform_(self.embedding.weight.data)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + x.new_tensor(self.offsets).unsqueeze(0)\n",
    "        return self.embedding(x)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T05:34:43.868835Z",
     "start_time": "2024-05-23T05:34:43.866163Z"
    }
   },
   "id": "8350678bd4770c63"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "class NeuralCollaborativeFiltering(torch.nn.Module):\n",
    "    def __init__(self, field_dims, user_field_idx, item_field_idx, embed_dim, mlp_dims, dropout):\n",
    "        super().__init__()\n",
    "        self.user_field_idx = user_field_idx\n",
    "        self.item_field_idx = item_field_idx\n",
    "        self.embedding = FeaturesEmbedding(field_dims, embed_dim)\n",
    "        self.embed_output_dim = len(field_dims) * embed_dim\n",
    "        self.mlp = MultiLayerPerceptron(self.embed_output_dim, mlp_dims, dropout, output_layer=False)\n",
    "        self.fc = torch.nn.Linear(mlp_dims[-1] + embed_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        user_x = x[:, self.user_field_idx].squeeze(1)\n",
    "        item_x = x[:, self.item_field_idx].squeeze(1)\n",
    "        x = self.mlp(x.view(-1, self.embed_output_dim))\n",
    "        gmf = user_x * item_x\n",
    "        x = torch.cat([gmf, x], dim=1)\n",
    "        x = self.fc(x).squeeze(1)\n",
    "        return torch.sigmoid(x)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T05:34:44.994914Z",
     "start_time": "2024-05-23T05:34:44.992324Z"
    }
   },
   "id": "13fd996cdecbd553"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def train(model, optimizer, data_loader, criterion, device, log_interval=100):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    av_loss = []\n",
    "    for i, (fields, target) in enumerate(data_loader):\n",
    "        fields, target = fields.to(device), target.to(device)\n",
    "        y = model(fields)\n",
    "        loss = criterion(y, target.float())\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    loss = total_loss / log_interval\n",
    "    av_loss.append(loss)\n",
    "    total_loss = 0\n",
    "    return np.mean(av_loss)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T05:34:49.307521Z",
     "start_time": "2024-05-23T05:34:49.304482Z"
    }
   },
   "id": "ed3505aa79cc935f"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def test(model, data_loader, device):\n",
    "    model.eval()\n",
    "    targets, predicts = list(), list()\n",
    "    with torch.no_grad():\n",
    "        for fields, target in data_loader:\n",
    "            fields, target = fields.to(device), target.to(device)\n",
    "            y = model(fields)\n",
    "            targets.extend(target.tolist())\n",
    "            predicts.extend(y.tolist())\n",
    "    return 5.* mean_squared_error(targets, predicts)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T05:34:50.931766Z",
     "start_time": "2024-05-23T05:34:50.929172Z"
    }
   },
   "id": "1aea056350222d08"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "ratings = pd.read_csv(\"./data/ratings.csv\")\n",
    "dataset = MovieLensDataset(ratings)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T05:36:38.001710Z",
     "start_time": "2024-05-23T05:36:37.973909Z"
    }
   },
   "id": "7dc8586474a18477"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "\n",
    "learning_rate = 0.001\n",
    "weight_decay = 1e-6\n",
    "batch_size = 2048\n",
    "epochs = 10\n",
    "model_name = \"ncf\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T05:36:39.495179Z",
     "start_time": "2024-05-23T05:36:39.493143Z"
    }
   },
   "id": "b9d52153d1e1eb5d"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "train_length = int(len(dataset) * 0.8)\n",
    "valid_length = int(len(dataset) * 0.1)\n",
    "test_length = len(dataset) - train_length - valid_length\n",
    "\n",
    "train_dataset, valid_dataset, test_dataset = torch.utils.data.random_split(\n",
    "        dataset, (train_length, valid_length, test_length))\n",
    "\n",
    "train_data_loader = DataLoader(train_dataset, batch_size=batch_size, num_workers=2)\n",
    "valid_data_loader = DataLoader(valid_dataset, batch_size=batch_size, num_workers=2)\n",
    "test_data_loader = DataLoader(test_dataset, batch_size=batch_size, num_workers=2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T05:36:40.910690Z",
     "start_time": "2024-05-23T05:36:40.900906Z"
    }
   },
   "id": "22129b0806ed13cf"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = NeuralCollaborativeFiltering(\n",
    "    dataset.field_dims, embed_dim=64, mlp_dims=(32, 32), dropout=0.2,\n",
    "    user_field_idx=dataset.user_field_idx,\n",
    "    item_field_idx=dataset.item_field_idx\n",
    ").to(device)\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=learning_rate, weight_decay=weight_decay)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T05:36:43.988292Z",
     "start_time": "2024-05-23T05:36:42.157259Z"
    }
   },
   "id": "76d5316aab6e3b5d"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "[671, 163949]"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(dataset.field_dims)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T05:36:43.992214Z",
     "start_time": "2024-05-23T05:36:43.990750Z"
    }
   },
   "id": "ef612c4482393b31"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'MovieLensDataset' on <module '__main__' (built-in)>\n"
     ]
    }
   ],
   "source": [
    "metric_values: list[float] = []\n",
    "loss_values: list[float] = []\n",
    "model_save_path = \"model.pth\"\n",
    "best_valid_loss = float(\"inf\")\n",
    "\n",
    "for epoch_i in tqdm(range(epochs)):\n",
    "    loss = train(model, optimizer, train_data_loader, criterion, device)\n",
    "    loss_values.append((epoch_i, loss))\n",
    "\n",
    "    valid_loss = test(model, valid_data_loader, device)\n",
    "\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), model_save_path)\n",
    "        print(f\"Epoch {epoch_i}: Validation loss improved, model saved at {model_save_path}\")\n",
    "\n",
    "    metric_valid = test(model, valid_data_loader, device)\n",
    "    metric_train = test(model, train_data_loader, device)\n",
    "    metric_test = test(model, test_data_loader, device)\n",
    "\n",
    "    metric_values.append((epoch_i, metric_train, metric_valid, metric_test))"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-05-23T05:36:45.087486Z"
    }
   },
   "id": "b92acee2e9e88f92"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "metric_values = np.array(metric_values)\n",
    "processed_loss_values = [x[1].item() for x in loss_values]\n",
    "f, ax = plt.subplots(1,2, figsize=(12, 6))\n",
    "ax[0].plot(processed_loss_values, label=\"train loss\", linewidth=2, color=\"#fc1c49\")\n",
    "ax[0].legend()\n",
    "ax[0].grid(linestyle=\"--\",which=\"major\")\n",
    "\n",
    "ax[1].plot(metric_values[:, 1], label=\"train mae\", linewidth=2, color=\"#fc1c49\")\n",
    "ax[1].plot(metric_values[:, 2], label=\"validation mae\", linewidth=2, color=\"#00a67d\")\n",
    "ax[1].plot(metric_values[:, 3], label=\"test mae\", linewidth=2, color=\"#005cc5\")\n",
    "ax[1].legend()\n",
    "ax[1].grid(linestyle=\"--\",which=\"major\")\n",
    "plt.suptitle(\"Train loss & Train/Validation/Test mae\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "5f1aca860fe0aead"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model(torch.tensor(np.array([[0, 1029]]).astype(np.int32)).to(device))"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "cc8ecaae0b21b640"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def round_off_rating(number):\n",
    "    return round(number * 2) / 2\n",
    "\n",
    "\n",
    "for i, (_, row) in enumerate(ratings[ratings[\"userId\"] == 200].iterrows()):\n",
    "    print(\"actual\", row[\"rating\"])\n",
    "    print(\"pred\", round_off_rating(model(torch.tensor(np.array([[row[\"userId\"] - 1, row[\"movieId\"] - 1]]).astype(np.int32)).to(device)).cpu().detach().numpy()[0] * 5.))\n",
    "    print(\"===\")\n",
    "\n",
    "    if i >= 4: break"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "dc2839d3bdf2902"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
