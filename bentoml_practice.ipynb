{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-20T03:59:07.820185Z",
     "start_time": "2024-05-20T03:59:04.281524Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import bentoml\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import BatchEncoding, BertTokenizer, BertForSequenceClassification, AdamW, pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "from typing import TypedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/Library/Python/3.9/site-packages/transformers/optimization.py:521: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/1200 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3ad54abd594b47cf9e23114f1f5a13b4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/800 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a05fa749e5514233acbcf968cf8a80a0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(\"ag_news\")\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=4)\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "class DatasetItem(TypedDict):\n",
    "    text: str\n",
    "    label: str\n",
    "\n",
    "\n",
    "def preprocess_data(dataset_item: DatasetItem) -> dict[str, torch.Tensor]:\n",
    "    return tokenizer(dataset_item[\"text\"], truncation=True, padding=\"max_length\", return_tensors=\"pt\")\n",
    "\n",
    "\n",
    "train_dataset = dataset[\"train\"].select(range(1200)).map(preprocess_data, batched=True)\n",
    "test_dataset = dataset[\"test\"].select(range(800)).map(preprocess_data, batched=True)\n",
    "\n",
    "train_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "test_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-20T04:00:01.764970Z"
    }
   },
   "id": "b4d6fcfe1e8ab89e"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 150/150 [13:47<00:00,  5.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Average Loss: 0.6095249705016613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 150/150 [13:49<00:00,  5.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Average Loss: 0.251108584155639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 150/150 [13:00<00:00,  5.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Average Loss: 0.13737154245997468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "num_epochs = 3\n",
    "losses: list[float] = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch + 1}\"):\n",
    "        inputs = {key: batch[key].to(device) for key in batch}\n",
    "        labels = inputs.pop(\"label\")\n",
    "        outputs = model(**inputs, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    average_loss = total_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch + 1}, Average Loss: {average_loss}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-20T04:44:50.094533Z",
     "start_time": "2024-05-20T04:04:12.727903Z"
    }
   },
   "id": "4b29db77abd2dc45"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(losses, color=\"#fc1c49\", linewidth=2)\n",
    "plt.xlabel(\"Step\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training Loss per Step Across Epochs\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f70fdb093404ab5f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader, desc=\"Evaluating\"):\n",
    "        inputs = {key: batch[key].to(device) for key in batch}\n",
    "        labels = inputs.pop(\"label\")\n",
    "        outputs = model(**inputs, labels=labels)\n",
    "        logits = outputs.logits\n",
    "        predicted_labels = torch.argmax(logits, dim=1)\n",
    "        correct += (predicted_labels == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "accuracy = correct / total\n",
    "\n",
    "print(\"\")\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "616c1855dc86f2e3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_predictions: list[int] = []\n",
    "all_labels: list[int] = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader, desc=\"Evaluating\"):\n",
    "        inputs = {key: batch[key].to(device) for key in batch}\n",
    "        labels = inputs.pop(\"label\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        predicted_labels = torch.argmax(logits, dim=1)\n",
    "\n",
    "        all_predictions.extend(predicted_labels.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ea8010887f8f1f1e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(all_labels, all_predictions)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"g\", cmap=sns.light_palette(\"#fc1c49\", as_cmap=True))\n",
    "plt.xlabel(\"Predicted labels\")\n",
    "plt.ylabel(\"True labels\")\n",
    "plt.title(\"Confusion Matrix Heatmap\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "33a08a4393fba973"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 모델 저장.\n",
    "name = \"bert_news_classification\"\n",
    "bentoml.transformers.save_model(\n",
    "    name,\n",
    "    pipeline(\"text-classification\", model=model, tokenizer=tokenizer)\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "be56de87a6a686e4"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Cell magic `%%` not found.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cat > service.py <<EOF\n",
    "import bentoml\n",
    "\n",
    "runner = bentoml.models.get(\"bert_news_classification:latest\").to_runner()\n",
    "svc = bentoml.Service(\n",
    "    name=\"bert_news_classification\", runners=[runner]\n",
    ")\n",
    "\n",
    "@svc.api(input=bentoml.io.Text(), output=bentoml.io.JSON())\n",
    "async def classify(text: str) -> dict[str, int|float]:\n",
    "    output = await runner.async_run(text, max_length=512)\n",
    "    return output[0]\n",
    "EOF"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-20T04:02:08.534462Z",
     "start_time": "2024-05-20T04:02:08.529905Z"
    }
   },
   "id": "a9ee0fb4c3748f22"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "%%script bash --bg\n",
    "bentoml serve service:svc"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-20T04:44:50.139851Z",
     "start_time": "2024-05-20T04:44:50.101201Z"
    }
   },
   "id": "8319bdff1e80ca8b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 아래와 같이 뜨면 정상 실행.\n",
    "# HTTP/1.1 200 OK\n",
    "# date: Sat, DD MM YYYY HH:mm:ss GMT\n",
    "# server: uvicorn\n",
    "# content-length: 1\n",
    "# content-type: text/plain; charset=utf-8\n",
    "\n",
    "!curl -I -X GET localhost:3000/healthz"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "49694c2118e04b9d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
